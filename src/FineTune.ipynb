{"cells":[{"cell_type":"markdown","metadata":{"id":"6ba6fbac-6b0f-48aa-960f-d1553cd06374"},"source":["## Imports/Aux"],"id":"6ba6fbac-6b0f-48aa-960f-d1553cd06374"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":714,"status":"ok","timestamp":1682294138945,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"},"user_tz":300},"id":"2b0c0761-b3e5-4080-815e-3c2c65b9331e","outputId":"0d5f1579-a76a-4043-8657-ea909db46a6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# colab only\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"id":"2b0c0761-b3e5-4080-815e-3c2c65b9331e"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5833,"status":"ok","timestamp":1682294145566,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"},"user_tz":300},"id":"dd769dc7-8bb3-4ff7-84cf-9f1c3b0cbf77","outputId":"a4d4b10a-e0e7-434c-b74a-4a6e1f83f324"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (4.8)\n","Requirement already satisfied: bitarray==2.7.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (2.7.3)\n","Requirement already satisfied: cffi==1.15.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (1.15.1)\n","Requirement already satisfied: click==8.1.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (8.1.3)\n","Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: contourpy==1.0.7 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.0.7)\n","Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (0.11.0)\n","Requirement already satisfied: cython==0.29.34 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (0.29.34)\n","Requirement already satisfied: fairseq==0.12.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (0.12.2)\n","Requirement already satisfied: filelock==3.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (3.11.0)\n","Requirement already satisfied: fonttools==4.39.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (4.39.3)\n","Requirement already satisfied: hydra-core==1.0.7 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.0.7)\n","Requirement already satisfied: jinja2==3.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (3.1.2)\n","Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.2.0)\n","Requirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (1.4.4)\n","Requirement already satisfied: lxml==4.9.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.9.2)\n","Requirement already satisfied: markupsafe==2.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 18)) (2.1.2)\n","Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 19)) (3.7.1)\n","Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 20)) (1.3.0)\n","Requirement already satisfied: networkx==3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (3.1)\n","Requirement already satisfied: numpy==1.24.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 22)) (1.24.2)\n","Requirement already satisfied: omegaconf==2.0.6 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 23)) (2.0.6)\n","Requirement already satisfied: packaging==23.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 24)) (23.1)\n","Requirement already satisfied: pandas==2.0.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 25)) (2.0.0)\n","Requirement already satisfied: pillow==9.5.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (9.5.0)\n","Requirement already satisfied: portalocker==2.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (2.7.0)\n","Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 28)) (2.21)\n","Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 29)) (3.0.9)\n","Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 30)) (2.8.2)\n","Requirement already satisfied: pytz==2023.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 31)) (2023.3)\n","Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 32)) (6.0)\n","Requirement already satisfied: regex==2023.3.23 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 33)) (2023.3.23)\n","Requirement already satisfied: sacrebleu==2.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 34)) (2.3.1)\n","Requirement already satisfied: sacremoses==0.0.53 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 35)) (0.0.53)\n","Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 36)) (1.2.2)\n","Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 37)) (1.10.1)\n","Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 38)) (1.16.0)\n","Requirement already satisfied: sympy==1.11.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 39)) (1.11.1)\n","Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 40)) (0.9.0)\n","Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 41)) (3.1.0)\n","Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 42)) (2.0.0+cu118)\n","Requirement already satisfied: torchaudio==2.0.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 43)) (2.0.1+cu118)\n","Requirement already satisfied: torchmetrics==0.11.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 44)) (0.11.4)\n","Requirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 45)) (4.65.0)\n","Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 46)) (4.5.0)\n","Requirement already satisfied: tzdata==2023.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 47)) (2023.3)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 19)) (5.12.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->-r requirements.txt (line 42)) (2.0.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 42)) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 42)) (3.25.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib==3.7.1->-r requirements.txt (line 19)) (3.15.0)\n"]}],"source":["# colab only\n","\n","%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project\n","! pip3 install -r requirements.txt"],"id":"dd769dc7-8bb3-4ff7-84cf-9f1c3b0cbf77"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5668,"status":"ok","timestamp":1682294151219,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"},"user_tz":300},"id":"nMpm1G4fkzG1","outputId":"bd99f8fa-b9e6-4ffc-f49c-ce83ed63cbb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final\n","\u001b[0m\u001b[01;34mfairseq\u001b[0m/  \u001b[01;34mfastBPE\u001b[0m/  \u001b[01;34mmosesdecoder\u001b[0m/  \u001b[01;34mNLP-Final-Project\u001b[0m/  repo_control.ipynb\n","env: MOSES=/content/gdrive/MyDrive/nlp-final/mosesdecoder\n","env: FASTBPE=/content/gdrive/MyDrive/nlp-final/fastBPE\n","/content/gdrive/MyDrive/nlp-final/fastBPE\n"]}],"source":["%cd /content/gdrive/MyDrive/nlp-final/\n","%ls\n","%pwd\n","#! git clone https://github.com/moses-smt/mosesdecoder.git\n","%env MOSES=/content/gdrive/MyDrive/nlp-final/mosesdecoder\n","\n","%env FASTBPE=/content/gdrive/MyDrive/nlp-final/fastBPE\n","%cd fastBPE\n","! g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast"],"id":"nMpm1G4fkzG1"},{"cell_type":"code","source":["# I'm trying to make new dict.txt/bpecodes for our data (with brain regions filled in)\n","# to solve the problem I was getting, which is that when I try to train the model\n","# on the filled-in data, it struggles to understand the language.\n","\n","\n","%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data\n","!perl ${MOSES}/scripts/tokenizer/tokenizer.perl -l en -a -threads 8 < /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.x > /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.x\n","!perl ${MOSES}/scripts/tokenizer/tokenizer.perl -l en -a -threads 8 < /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.y > /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFM42BElXt2w","executionInfo":{"status":"ok","timestamp":1682291356319,"user_tz":300,"elapsed":2229,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}},"outputId":"7291067e-7bf9-4d0f-be1e-0779d208f107"},"id":"vFM42BElXt2w","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/nlp-final/fastBPE\n","! ./fast getvocab /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.x /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.y > /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/tagged_vocab.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5S_wOYqLPvF","executionInfo":{"status":"ok","timestamp":1682291422682,"user_tz":300,"elapsed":636,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}},"outputId":"d356906f-f6ff-4731-9674-47536a5e5c15"},"id":"n5S_wOYqLPvF","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/fastBPE\n","Loading vocabulary from /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.x ...\n","Read 57418 words (6075 unique) from text file.\n","Loading vocabulary from /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.y ...\n","Read 22699 words (6083 unique) from text file.\n"]}]},{"cell_type":"code","source":["import string\n","%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data\n","\n","with open('tagged_vocab.txt') as f1:\n","  tagged_lines = f1.readlines()\n","\n","with open('dict.txt') as f2:\n","  dict_lines = f2.readlines()\n","\n","d2 = {}\n","for line in tagged_lines:\n","  #line = line.translate(str.maketrans('', '', string.punctuation))\n","  split_line = line.split(' ')\n","  d2[split_line[0]] = int(split_line[1])\n","\n","d1 = {}\n","for line in dict_lines:\n","  split_line = line.split(' ')\n","  d1[split_line[0]] = int(split_line[1])\n","\n","for k, v in d2.items():\n","  k1 = k\n","  if k in d1:\n","    d1[k] += int(v)\n","  else:\n","    d1[k] = int(v)\n","\n","with open('comb_dict.txt', 'w') as f3:\n","  for k, v in d1.items():\n","    f3.write(k + \" \" + str(v) + \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbScvIEZQfLW","executionInfo":{"status":"ok","timestamp":1682291537517,"user_tz":300,"elapsed":154,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}},"outputId":"b75ea707-301e-4cc0-999b-356472853943"},"id":"qbScvIEZQfLW","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data\n"]}]},{"cell_type":"code","source":["# after the preceeding cell, I manually deleted vocab words that aren't useful\n","# for our purposes so it matched the BioGPT vocab length\n","\n","# if this fails, could see how to replicate the current bpecodes\n","\n","%cd /content/gdrive/MyDrive/nlp-final/fastBPE\n","\n","! ./fast learnbpe 40000 /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.x /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.y > /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/my_bpecodes\n","\n","# using these bpe codes failed, but also possibly because I generated them\n","# with the blanks data and tried to use them on the pos-only data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-kNm5PAegiL","executionInfo":{"status":"ok","timestamp":1682293323745,"user_tz":300,"elapsed":10580,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}},"outputId":"ffc151b9-76a6-4e23-8e18-c8f39dd65e00"},"id":"N-kNm5PAegiL","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/fastBPE\n","Loading vocabulary from /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.x ...\n","Read 57418 words (6075 unique) from text file.\n","Loading vocabulary from /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/tagged_data/train_tags.tok.y ...\n","Read 22699 words (6083 unique) from text file.\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Ic1rimHil7pm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682294164737,"user_tz":300,"elapsed":13529,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}},"outputId":"807e71ac-ee77-4948-8579-037cb437eb1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/utils\n","Preprocessing train\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Loading codes from ../data/tagged_data/pos_only/bpecodes ...\n","Read 40000 codes from the codes file.\n","Loading vocabulary from ../data/tagged_data/pos_only/relis_train.tok.x ...\n","Read 12194 words (2246 unique) from text file.\n","Applying BPE to ../data/tagged_data/pos_only/relis_train.tok.x ...\n","Modified 12194 words from text file.\n","Loading codes from ../data/tagged_data/pos_only/bpecodes ...\n","Read 40000 codes from the codes file.\n","Loading vocabulary from ../data/tagged_data/pos_only/relis_train.tok.y ...\n","Read 5222 words (539 unique) from text file.\n","Applying BPE to ../data/tagged_data/pos_only/relis_train.tok.y ...\n","Modified 5222 words from text file.\n","Preprocessing valid\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Loading codes from ../data/tagged_data/pos_only/bpecodes ...\n","Read 40000 codes from the codes file.\n","Loading vocabulary from ../data/tagged_data/pos_only/relis_valid.tok.x ...\n","Read 13469 words (1295 unique) from text file.\n","Applying BPE to ../data/tagged_data/pos_only/relis_valid.tok.x ...\n","Modified 13469 words from text file.\n","Loading codes from ../data/tagged_data/pos_only/bpecodes ...\n","Read 40000 codes from the codes file.\n","Loading vocabulary from ../data/tagged_data/pos_only/relis_valid.tok.y ...\n","Read 2200 words (8 unique) from text file.\n","Applying BPE to ../data/tagged_data/pos_only/relis_valid.tok.y ...\n","Modified 2200 words from text file.\n","Preprocessing test\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Loading codes from ../data/tagged_data/pos_only/bpecodes ...\n","Read 40000 codes from the codes file.\n","Loading vocabulary from ../data/tagged_data/pos_only/relis_test.tok.x ...\n","Read 7375 words (1520 unique) from text file.\n","Applying BPE to ../data/tagged_data/pos_only/relis_test.tok.x ...\n","Modified 7375 words from text file.\n","Loading codes from ../data/tagged_data/pos_only/bpecodes ...\n","Read 40000 codes from the codes file.\n","Loading vocabulary from ../data/tagged_data/pos_only/relis_test.tok.y ...\n","Read 2616 words (8 unique) from text file.\n","Applying BPE to ../data/tagged_data/pos_only/relis_test.tok.y ...\n","Modified 2616 words from text file.\n","2023-04-23 23:55:55.659159: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-23 23:55:57.918585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-04-23 23:56:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-04-23 23:56:00 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='x', target_lang='y', trainpref='../data/tagged_data/pos_only/relis_train.tok.bpe', validpref='../data/tagged_data/pos_only/relis_valid.tok.bpe', testpref='../data/tagged_data/pos_only/relis_test.tok.bpe', align_suffix=None, destdir='../data/tagged_data/pos_only/relis-bin', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict='../data/tagged_data/pos_only/comb_dict.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=8, dict_only=False)\n","2023-04-23 23:56:00 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n","2023-04-23 23:56:01 | INFO | fairseq_cli.preprocess | [x] ../data/tagged_data/pos_only/relis_train.tok.bpe.x: 442 sents, 13736 tokens, 0.0% replaced (by <unk>)\n","2023-04-23 23:56:01 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n","2023-04-23 23:56:02 | INFO | fairseq_cli.preprocess | [x] ../data/tagged_data/pos_only/relis_valid.tok.bpe.x: 275 sents, 15843 tokens, 0.0% replaced (by <unk>)\n","2023-04-23 23:56:02 | INFO | fairseq_cli.preprocess | [x] Dictionary: 42384 types\n","2023-04-23 23:56:02 | INFO | fairseq_cli.preprocess | [x] ../data/tagged_data/pos_only/relis_test.tok.bpe.x: 327 sents, 8831 tokens, 0.0% replaced (by <unk>)\n","2023-04-23 23:56:02 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n","2023-04-23 23:56:02 | INFO | fairseq_cli.preprocess | [y] ../data/tagged_data/pos_only/relis_train.tok.bpe.y: 442 sents, 6165 tokens, 0.0% replaced (by <unk>)\n","2023-04-23 23:56:02 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n","2023-04-23 23:56:03 | INFO | fairseq_cli.preprocess | [y] ../data/tagged_data/pos_only/relis_valid.tok.bpe.y: 275 sents, 3025 tokens, 0.0% replaced (by <unk>)\n","2023-04-23 23:56:03 | INFO | fairseq_cli.preprocess | [y] Dictionary: 42384 types\n","2023-04-23 23:56:03 | INFO | fairseq_cli.preprocess | [y] ../data/tagged_data/pos_only/relis_test.tok.bpe.y: 327 sents, 3597 tokens, 0.0% replaced (by <unk>)\n","2023-04-23 23:56:03 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../data/tagged_data/pos_only/relis-bin\n"]}],"source":["%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/utils\n","\n","! bash preprocess.sh"],"id":"Ic1rimHil7pm"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11510,"status":"ok","timestamp":1682294190381,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"},"user_tz":300},"id":"D5UaB09XRRwN","outputId":"ce6722c3-4a85-477c-8cf3-b5d8154ed4ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/utils\n","2023-04-23 23:56:21.403440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-23 23:56:22.251530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-04-23 23:56:23 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n","2023-04-23 23:56:23 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-04-23 23:56:28 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/src', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '../checkpoints/RE-WhiteText-BioGPT/positive_tagged', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '../checkpoints/Pre-trained-BioGPT/checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_prompt_biogpt', 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 24, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': True, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'decoder_xformers_att_config': None, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': 1024, 'tpu': False}, 'task': {'_name': 'language_modeling_prompt', 'data': '../data/tagged_data/pos_only', 'sample_break_mode': none, 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': 1024, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'source_lang': None, 'target_lang': None, 'max_source_positions': 640, 'manual_prompt': None, 'learned_prompt': 9, 'learned_prompt_pattern': 'learned', 'prefix': False, 'sep_token': '<seqsep>'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 100, 'warmup_init_lr': 1e-07, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\n","    sys.exit(cli_main())\n","  File \"/usr/local/lib/python3.9/dist-packages/fairseq_cli/train.py\", line 557, in cli_main\n","    distributed_utils.call_main(cfg, main)\n","  File \"/usr/local/lib/python3.9/dist-packages/fairseq/distributed/utils.py\", line 369, in call_main\n","    main(cfg, **kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/fairseq_cli/train.py\", line 87, in main\n","    task = tasks.setup_task(cfg.task)\n","  File \"/usr/local/lib/python3.9/dist-packages/fairseq/tasks/__init__.py\", line 46, in setup_task\n","    return task.setup_task(cfg, **kwargs)\n","  File \"/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/src/language_modeling_prompt.py\", line 133, in setup_task\n","    raise Exception(\n","Exception: Could not infer language pair, please provide it explicitly\n"]}],"source":["%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/utils\n","! bash train.sh"],"id":"D5UaB09XRRwN"},{"cell_type":"code","execution_count":5,"metadata":{"id":"ae029015-ac48-4243-b609-d680b007e6cb","executionInfo":{"status":"ok","timestamp":1682284740578,"user_tz":300,"elapsed":13,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}}},"outputs":[],"source":["# colab only\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/NLP_Final_Project/src')"],"id":"ae029015-ac48-4243-b609-d680b007e6cb"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682284740579,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"},"user_tz":300},"id":"709b9f40-6594-46f8-b4e5-9579f0161330","outputId":"c2e445f5-685c-446d-f855-5688816e7998"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src\n"]}],"source":["%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src\n","\n","data_dir = '/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/relis-bin'\n","model_dir = '/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/checkpoints/RE-WhiteText-BioGPT'\n","model_file = 'checkpoint_avg_masked_pos.pt'\n","src_file = '/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/data/blanks/relis_valid.tok.bpe.x'\n","output_file = 'pos_valid_inference_18_epochs.txt'\n","beam = 1\n","decoding_length = 1024\n","\n","#! python utils/average_checkpoints.py --inputs='/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/checkpoints/blanks/RE-WhiteText-BioGPT' --output='/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src/checkpoints/RE-WhiteText-BioGPT/blanks/checkpoint_avg.pt' --num-epoch-checkpoints=2"],"id":"709b9f40-6594-46f8-b4e5-9579f0161330"},{"cell_type":"markdown","metadata":{"id":"c4e84cc4-9eec-4945-a6c6-8ded41d4b61e"},"source":["## Model Setup"],"id":"c4e84cc4-9eec-4945-a6c6-8ded41d4b61e"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235506,"status":"ok","timestamp":1682284976076,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"},"user_tz":300},"id":"47f9fa07-94e0-48b8-9842-3a0b63ecae28","outputId":"b7838b91-3d5f-4c99-f5eb-528a1250d90d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src\n"]}],"source":["%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src\n","\n","from src.transformer_lm_prompt import TransformerLanguageModelPrompt\n","\n","src_inputs = []\n","with open(src_file) as reader:\n","    for line in reader:\n","        src_inputs.append(line.strip())\n","    \n","\n","m = TransformerLanguageModelPrompt.from_pretrained(\n","    model_dir, \n","    model_file, \n","    data_dir,\n","    max_len_b=decoding_length,\n","    max_tokens=12000,)\n","\n","if m.cfg.common.fp16:\n","    print('Converting to float 16')\n","    m.half()\n","m.cuda()\n","\n","outputs = m.sample(src_inputs, beam=beam)\n","\n","with open(f\"{output_file}\", \"w\", encoding='utf8') as fw:\n","    for i in range(len(outputs)):\n","        fw.write(outputs[i] + '\\n')"],"id":"47f9fa07-94e0-48b8-9842-3a0b63ecae28"},{"cell_type":"code","source":["# debpe\n","! sed -i \"s/@@ //g\" pos_valid_inference_18_epochs.txt\n","# detok\n","! perl ${MOSES}/scripts/tokenizer/detokenizer.perl -l en -a < pos_valid_inference_18_epochs.txt > pos_valid_inference_18_epochs.txt.detok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHpi1-qxjEN-","executionInfo":{"status":"ok","timestamp":1682284978875,"user_tz":300,"elapsed":2816,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}},"outputId":"61f98e4b-ea92-4a01-c5a2-056447db49ec"},"id":"vHpi1-qxjEN-","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Detokenizer Version $Revision: 4134 $\n","Language: en\n"]}]},{"cell_type":"markdown","source":["## Calculating metrics"],"metadata":{"id":"6QfsN7gV6ykW"},"id":"6QfsN7gV6ykW"},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src\n","\n","with open('pos_valid_inference_18_epochs.txt.detok') as f1:\n","  pred_lines = f1.readlines()\n","\n","with open('data/blanks/relis_valid.y') as f2:\n","  gold_lines = f2.readlines()\n","\n","true_pos = 0\n","false_pos = 0\n","false_neg = 0\n","\n","template = \"the relation between BR1 and BR2 exists.\\n\".strip()\n","\n","for pred, gold in zip(pred_lines, gold_lines):\n","  split_line = pred.split(\"learned9\")\n","  gold = gold.strip()\n","  \n","  if gold == template:\n","    if split_line[1].strip() == template:\n","      true_pos += 1\n","    else:\n","      false_neg += 1\n","  else:\n","    if split_line[1].strip() == template:\n","      false_pos += 1\n","\n","precision = true_pos/(true_pos + false_pos)\n","recall = true_pos/(true_pos + false_neg)\n","\n","print(\"Precision = \", precision)\n","print(\"Recall = \", recall)\n","print(\"F1 = \", 2*((precision*recall)/(precision + recall)))\n","print(\"F2 = \", 5*((precision*recall)/((4*precision) + recall)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0A6Y-3q4NP6","executionInfo":{"status":"ok","timestamp":1682285001053,"user_tz":300,"elapsed":1095,"user":{"displayName":"Margaret von Ebers","userId":"11984602722974950585"}},"outputId":"66c12649-57c9-4ea8-9812-e8ce167ca286"},"id":"t0A6Y-3q4NP6","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/nlp-final/NLP-Final-Project/src\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","yes\n","Precision =  0.13143989431968295\n","Recall =  0.7236363636363636\n","F1 =  0.22247065399664614\n","F2 =  0.3806426931905126\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}